{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_gansynth.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtXQBH4gH7Pk2xvGJYUi5B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_music/blob/main/section_4/02_gansynth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPkdg9jTjkTd"
      },
      "source": [
        "# GANSynthによる作曲\n",
        "「GANSynth」により、MIDIデータに楽器の音声を付与します。  \n",
        "生成には時間がかかるので、「編集」→「ノートブックの設定」→「ハードウェア アクセラレータ」で「GPU」を選択しておきましょう。  \n",
        "このノートブックのコードは、以下のリンク先のコードを参考にしています。  \n",
        "http://goo.gl/magenta/gansynth-demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKARfZNZ_EA"
      },
      "source": [
        "## ライブラリのインストール\n",
        "Magentaと共に、音楽生成用のライブラリpyFluidSynth、MIDIデータを処理するためのpretty_midiなどをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRTOCXhK9YAM"
      },
      "source": [
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "!pip install -qU magenta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5-xG4QVx1iK"
      },
      "source": [
        "## ライブラリの導入\n",
        "Magentaの必要な機能と、NumPyなどのライブラリを導入します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuBbvFkNssM3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import tensorflow.compat.v1 as tf\n",
        "import librosa\n",
        "\n",
        "import magenta.music as mm\n",
        "from magenta.models.gansynth.lib import flags as lib_flags\n",
        "from magenta.models.gansynth.lib import generate_util as gu\n",
        "from magenta.models.gansynth.lib import model as lib_model\n",
        "from magenta.models.gansynth.lib import util\n",
        "from note_seq.notebook_utils import colab_play as play\n",
        "\n",
        "import note_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XAYVxmpyLQb"
      },
      "source": [
        "## 各設定値\n",
        "曲の生成に関する各値を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD3DbsM_rBP5"
      },
      "source": [
        "BATCH_SIZE = 16  # 一度に扱うデータ数\n",
        "SR = 16000  # サンプリングレート"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDC_l0Guz-go"
      },
      "source": [
        "## 関数の設定\n",
        "音声を処理する関数です。  \n",
        "以下のリンク先のコードを使用しています。  \n",
        "http://goo.gl/magenta/gansynth-demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSrXsUPJczea"
      },
      "source": [
        "def load_midi(midi_path, min_pitch=36, max_pitch=84):\n",
        "  \"\"\"Load midi as a notesequence.\"\"\"\n",
        "  midi_path = util.expand_path(midi_path)\n",
        "  ns = note_seq.midi_file_to_sequence_proto(midi_path)\n",
        "  pitches = np.array([n.pitch for n in ns.notes])\n",
        "  velocities = np.array([n.velocity for n in ns.notes])\n",
        "  start_times = np.array([n.start_time for n in ns.notes])\n",
        "  end_times = np.array([n.end_time for n in ns.notes])\n",
        "  valid = np.logical_and(pitches >= min_pitch, pitches <= max_pitch)\n",
        "  notes = {'pitches': pitches[valid],\n",
        "           'velocities': velocities[valid],\n",
        "           'start_times': start_times[valid],\n",
        "           'end_times': end_times[valid]}\n",
        "  return ns, notes\n",
        "\n",
        "def get_envelope(t_note_length, t_attack=0.010, t_release=0.3, sr=16000):\n",
        "  \"\"\"Create an attack sustain release amplitude envelope.\"\"\"\n",
        "  t_note_length = min(t_note_length, 3.0)\n",
        "  i_attack = int(sr * t_attack)\n",
        "  i_sustain = int(sr * t_note_length)\n",
        "  i_release = int(sr * t_release)\n",
        "  i_tot = i_sustain + i_release  # attack envelope doesn't add to sound length\n",
        "  envelope = np.ones(i_tot)\n",
        "  # Linear attack\n",
        "  envelope[:i_attack] = np.linspace(0.0, 1.0, i_attack)\n",
        "  # Linear release\n",
        "  envelope[i_sustain:i_tot] = np.linspace(1.0, 0.0, i_release)\n",
        "  return envelope\n",
        "\n",
        "def combine_notes(audio_notes, start_times, end_times, velocities, sr=16000):\n",
        "  \"\"\"Combine audio from multiple notes into a single audio clip.\n",
        "\n",
        "  Args:\n",
        "    audio_notes: Array of audio [n_notes, audio_samples].\n",
        "    start_times: Array of note starts in seconds [n_notes].\n",
        "    end_times: Array of note ends in seconds [n_notes].\n",
        "    sr: Integer, sample rate.\n",
        "\n",
        "  Returns:\n",
        "    audio_clip: Array of combined audio clip [audio_samples]\n",
        "  \"\"\"\n",
        "  n_notes = len(audio_notes)\n",
        "  clip_length = end_times.max() + 3.0\n",
        "  audio_clip = np.zeros(int(clip_length) * sr)\n",
        "\n",
        "  for t_start, t_end, vel, i in zip(start_times, end_times, velocities, range(n_notes)):\n",
        "    # Generate an amplitude envelope\n",
        "    t_note_length = t_end - t_start\n",
        "    envelope = get_envelope(t_note_length)\n",
        "    length = len(envelope)\n",
        "    audio_note = audio_notes[i, :length] * envelope\n",
        "    # Normalize\n",
        "    audio_note /= audio_note.max()\n",
        "    audio_note *= (vel / 127.0)\n",
        "    # Add to clip buffer\n",
        "    clip_start = int(t_start * sr)\n",
        "    clip_end = clip_start + length\n",
        "    audio_clip[clip_start:clip_end] += audio_note\n",
        "\n",
        "  # Normalize\n",
        "  audio_clip /= audio_clip.max()\n",
        "  audio_clip /= 2.0\n",
        "  return audio_clip\n",
        "\n",
        "# Plotting tools\n",
        "def specplot(audio_clip):\n",
        "  p_min = np.min(36)\n",
        "  p_max = np.max(84)\n",
        "  f_min = librosa.midi_to_hz(p_min)\n",
        "  f_max = 2 * librosa.midi_to_hz(p_max)\n",
        "  octaves = int(np.ceil(np.log2(f_max) - np.log2(f_min)))\n",
        "  bins_per_octave = 36\n",
        "  n_bins = int(bins_per_octave * octaves)\n",
        "  C = librosa.cqt(audio_clip, sr=SR, hop_length=2048, fmin=f_min, n_bins=n_bins, bins_per_octave=bins_per_octave)\n",
        "  power = 10 * np.log10(np.abs(C)**2 + 1e-6)\n",
        "  plt.matshow(power[::-1, 2:-2], aspect='auto', cmap=plt.cm.magma)\n",
        "  plt.yticks([])\n",
        "  plt.xticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUhjLcWwzwp4"
      },
      "source": [
        "## GANSynthのモデル\n",
        "パスを指定し、GANSynthの学習済みモデルを読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyvtNnTVXU8k"
      },
      "source": [
        "tf.disable_v2_behavior()  # tensorflow2で1.xのコードを動かす\n",
        "tf.reset_default_graph()  # tensorflowのグラフをリセット\n",
        "\n",
        "model_dir = \"gs://magentadata/models/gansynth/acoustic_only\"\n",
        "flags = lib_flags.Flags({\n",
        "    \"batch_size_schedule\": [BATCH_SIZE],\n",
        "    \"tfds_data_dir\": \"gs://tfds-data/datasets\",\n",
        "})\n",
        "model = lib_model.Model.load_from_path(model_dir, flags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhwQ_hSyqD1S"
      },
      "source": [
        "「01_multitrack_musicvae.ipynb」で作成した、「conditional_vae.mid」を、ノートブック左の「ファイル」にアップロードしましょう。  \n",
        "以下は、このファイルを読み込むコードです。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG45NrZ2cIE6"
      },
      "source": [
        "midi_path = \"conditional_vae.mid\"\n",
        "ns, notes = load_midi(midi_path)\n",
        "\n",
        "note_seq.plot_sequence(ns)\n",
        "note_seq.play_sequence(ns, synth=note_seq.fluidsynth) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECdIgyBm16mW"
      },
      "source": [
        "GANSynthにより、読み込んだMIDIデータに楽器の音声を付与します。   \n",
        "楽器はランダムにゆっくりと切り替わります。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyfZOuo1WgbS"
      },
      "source": [
        "seconds_per_instrument = 5  # 楽器が切り替わる間隔\n",
        "\n",
        "# 潜在変数がランダムにゆっくりと変化\n",
        "z_instruments, t_instruments = gu.get_random_instruments(  # 潜在変数とその時間\n",
        "    model,\n",
        "    notes[\"end_times\"][-1],\n",
        "    secs_per_instrument=seconds_per_instrument)\n",
        "\n",
        "# 各noteの潜在変数を取得\n",
        "z_notes = gu.get_z_notes(notes[\"start_times\"], z_instruments, t_instruments)\n",
        "\n",
        "# 各ノートの音声を生成\n",
        "audio_notes = model.generate_samples_from_z(z_notes, notes[\"pitches\"])\n",
        "\n",
        "# 1つの音声にまとめる\n",
        "audio = combine_notes(\n",
        "    audio_notes,\n",
        "    notes[\"start_times\"],\n",
        "    notes[\"end_times\"],\n",
        "    notes[\"velocities\"]\n",
        "    )\n",
        "\n",
        "specplot(audio)  # スペクトログラムの表示\n",
        "play(audio, sample_rate=SR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhtRBNNf05CA"
      },
      "source": [
        "音声ををwavデータに変換し、保存してダウンロードします。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl883QBOr6le"
      },
      "source": [
        "file_name = \"gansynth.wav\"\n",
        "gu.save_wav(audio, file_name)\n",
        "files.download(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}